{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "CMD=[\"perl\", \"../english_testbed/data/2015/evaluate/correlation-noconfidence.pl\"]\n",
    "class Opts:\n",
    "    verbose=False\n",
    "    filter_test=\".*\"\n",
    "    \n",
    "opts=Opts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_2015_DATADIR=\"english_testbed/analysis/2015/training/results/\"\n",
    "TEST_2015_DATADIR=\"english_testbed/analysis/2015/testing/results\"\n",
    "TEST_2016_DATADIR=\"english_testbed/analysis/2016/testing/results\"\n",
    "TEST_2015_DIR=\"english_testbed/data/2015/test/\"\n",
    "TEST_2016_DIR=\"english_testbed/data/2016/test/\"\n",
    "TRAIN_2015_NAMEFILES=[\n",
    "  \"STS.2012.test.input.MSRpar.txt\",\n",
    "  \"STS.2012.test.input.MSRvid.txt\",\n",
    "  \"STS.2012.test.input.SMTeuroparl.txt\",\n",
    "  \"STS.2012.test.input.surprise.OnWN.txt\",\n",
    "  \"STS.2012.test.input.surprise.SMTnews.txt\",\n",
    "  \"STS.2012.train.input.MSRpar.txt\",\n",
    "  \"STS.2012.train.input.MSRvid.txt\",\n",
    "  \"STS.2012.train.input.SMTeuroparl.txt\",\n",
    "  \"STS.2013.test.input.FNWN.txt\",\n",
    "  \"STS.2013.test.input.headlines.txt\",\n",
    "  \"STS.2013.test.input.OnWN.txt\",\n",
    "  \"STS.2013.test.input.SMT.txt\",\n",
    "  \"STS.2014.test.input.deft-forum.txt\",\n",
    "  \"STS.2014.test.input.deft-news.txt\",\n",
    "  \"STS.2014.test.input.headlines.txt\",\n",
    "  \"STS.2014.test.input.images.txt\",\n",
    "  \"STS.2014.test.input.OnWN.txt\",\n",
    "  \"STS.2014.test.input.tweet-news.txt\"]\n",
    "TEST_2015_NAMEFILES=[\n",
    "  \"STS.input.answers-forums.txt\",\n",
    "  \"STS.input.answers-students.txt\",\n",
    "  \"STS.input.belief.txt\",\n",
    "  \"STS.input.headlines.txt\",\n",
    "  \"STS.input.images.txt\"]\n",
    "TEST_2016_NAMEFILES=[\n",
    "  \"STS2016.input.answer-answer.txt\",\n",
    "  \"STS2016.input.headlines.txt\",\n",
    "  \"STS2016.input.plagiarism.txt\",\n",
    "  \"STS2016.input.postediting.txt\",\n",
    "  \"STS2016.input.question-question.txt\"\n",
    "]\n",
    "\n",
    "OUTPUT_DIR='output'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_data_file(filename,nan=False):\n",
    "    GS=[]\n",
    "    DATA=[]\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            line=line.strip()\n",
    "            bits=line.split()\n",
    "           \n",
    "            #print [x.split(':') for x in bits[1:]]\n",
    "            line=[ float(x.split(':')[1]) for x in bits[1:]]\n",
    "            line=np.nan_to_num(line)\n",
    "            if not np.isfinite(line).all():\n",
    "                print \"problem\"\n",
    "                print line\n",
    "                if nan:\n",
    "                continue\n",
    "            GS.append(float(bits[0]))    \n",
    "            DATA.append(np.nan_to_num(line))\n",
    "    return GS,np.array(DATA)\n",
    "\n",
    "def make_data_name(dirname,filename,replace=True):\n",
    "    if replace:\n",
    "        filename=filename.replace(\".txt\",\".dat\")\n",
    "    else:\n",
    "        filename=filename+\".dat\"\n",
    "    return os.path.join(\"..\",dirname,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape para STS.2012.test.input.MSRpar.txt (750, 16)\n",
      "Shape para STS.2012.test.input.MSRvid.txt (750, 16)\n",
      "Shape para STS.2012.test.input.SMTeuroparl.txt (459, 16)\n",
      "Shape para STS.2012.test.input.surprise.OnWN.txt (750, 16)\n",
      "Shape para STS.2012.test.input.surprise.SMTnews.txt (399, 16)\n",
      "Shape para STS.2012.train.input.MSRpar.txt (750, 16)\n",
      "Shape para STS.2012.train.input.MSRvid.txt (750, 16)\n",
      "Shape para STS.2012.train.input.SMTeuroparl.txt (734, 16)\n",
      "Shape para STS.2013.test.input.FNWN.txt (189, 16)\n",
      "Shape para STS.2013.test.input.headlines.txt (750, 16)\n",
      "Shape para STS.2013.test.input.OnWN.txt (561, 16)\n",
      "Shape para STS.2013.test.input.SMT.txt (750, 16)\n",
      "Shape para STS.2014.test.input.deft-forum.txt (450, 16)\n",
      "Shape para STS.2014.test.input.deft-news.txt (300, 16)\n",
      "Shape para STS.2014.test.input.headlines.txt (750, 16)\n",
      "Shape para STS.2014.test.input.images.txt (750, 16)\n",
      "Shape para STS.2014.test.input.OnWN.txt (750, 16)\n",
      "Shape para STS.2014.test.input.tweet-news.txt (750, 16)\n",
      "Shape para STS.input.answers-forums.txt (2000, 16)\n",
      "Shape para STS.input.answers-students.txt (1500, 16)\n",
      "Shape para STS.input.belief.txt (2000, 16)\n",
      "Shape para STS.input.headlines.txt (1500, 16)\n",
      "Shape para STS.input.images.txt (1500, 16)\n",
      "Total train data files 2015: 18\n",
      "Total test  data files 2015: 5\n"
     ]
    }
   ],
   "source": [
    "DATA_TRAIN_2015={}\n",
    "DATA_TEST_2015={}\n",
    "\n",
    "for filename in TRAIN_2015_NAMEFILES:\n",
    "    filename_=make_data_name(TRAIN_2015_DATADIR,filename)\n",
    "    gs,data=read_data_file(filename_)\n",
    "    DATA_TRAIN_2015[filename]=(gs,data)\n",
    "    print \"Shape para\",filename,data.shape\n",
    "\n",
    "for filename in TEST_2015_NAMEFILES:\n",
    "    filename_=make_data_name(TEST_2015_DATADIR,filename)\n",
    "    gs,data=read_data_file(filename_)\n",
    "    DATA_TEST_2015[filename]=(gs,data)\n",
    "    print \"Shape para\",filename,data.shape\n",
    "    \n",
    "print \"Total train data files 2015:\",len(DATA_TRAIN_2015)\n",
    "print \"Total test  data files 2015:\",len(DATA_TEST_2015)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape (11342, 16)\n",
      "Training shape (11342,)\n"
     ]
    }
   ],
   "source": [
    "X_train_2015=[]\n",
    "Y_train_2015=[]\n",
    "X_test_2015=[]\n",
    "Y_test_2015=[]\n",
    "\n",
    "for filename,(gs,data) in DATA_TRAIN_2015.iteritems():\n",
    "    X_train_2015.append(data)\n",
    "    Y_train_2015.append(gs)\n",
    "X_train_2015=np.concatenate(X_train_2015,axis=0)\n",
    "Y_train_2015=np.concatenate(Y_train_2015,axis=0)\n",
    "\n",
    "\n",
    "print \"Training shape\", X_train_2015.shape\n",
    "print \"Training shape\", Y_train_2015.shape\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-4a0aa7e6863b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mX_train_2015\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_2015\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_2015\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train_2015\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \"\"\"\n\u001b[0;32m    194\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;31m# Pre-sort indices to avoid that each individual tree of the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features)\u001b[0m\n\u001b[0;32m    344\u001b[0m                              array.ndim)\n\u001b[0;32m    345\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     50\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     51\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 52\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "X_train_2015=np.nan_to_num(X_train_2015)\n",
    "rf= RandomForestRegressor(n_estimators=100,warm_start=True)\n",
    "rf.fit(X_train_2015,Y_train_2015)\n",
    "\n",
    "\n",
    "for filename,(gs,data) in DATA_TEST_2015.iteritems():\n",
    "    gs_=rf.predict(data)\n",
    "\n",
    "    print \"===== For\",filename\n",
    "    #print \"EVS:\", explained_variance_score(gs,gs_)\n",
    "    #print \"MAE:\", mean_absolute_error(gs,gs_)\n",
    "    #print \"MSR:\", mean_squared_error(gs,gs_)\n",
    "    #print \"mAE:\", median_absolute_error(gs,gs_)\n",
    "    #print \"R2 :\", r2_score(gs,gs_)\n",
    "    filename_=os.path.join(\"..\",OUTPUT_DIR,filename)\n",
    "    testfilename=os.path.join(filename)\n",
    "    testfilename=testfilename.replace(\"STS.input\",\"STS.2015.gs\")\n",
    "\n",
    "    fn=open(filename_,'w')\n",
    "    for pred in gs_: \n",
    "        print >> fn, \"{0:1.3f}\".format(pred)\n",
    "    fn.close()\n",
    "    print \"PEA:\",utils.eval(CMD,os.path.join(\"..\",TEST_2015_DIR,testfilename),filename_)\n",
    "\n",
    "\n",
    "    \n",
    "    #===== For STS.input.answers-forums.txt\n",
    "    #PEA: 0.63331\n",
    "    #===== For STS.input.images.txt\n",
    "    #PEA: 0.81768\n",
    "    #===== For STS.input.answers-students.txt\n",
    "    #PEA: 0.63893\n",
    "    #===== For STS.input.headlines.txt\n",
    "    #PEA: 0.81666\n",
    "    #===== For STS.input.belief.txt\n",
    "    #PEA: 0.72389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape para STS2016.input.answer-answer.txt (1572, 16)\n",
      "Shape para STS2016.input.headlines.txt (1498, 16)\n",
      "Shape para STS2016.input.plagiarism.txt (1271, 16)\n",
      "Shape para STS2016.input.postediting.txt (3287, 16)\n",
      "Shape para STS2016.input.question-question.txt (1555, 16)\n",
      "Total train data files 2016: 23\n"
     ]
    }
   ],
   "source": [
    "DATA_TRAIN_2016={}\n",
    "DATA_TEST_2016={}\n",
    "\n",
    "for filename,data in DATA_TRAIN_2015.iteritems():\n",
    "    DATA_TRAIN_2016[filename]=data\n",
    "for filename,data in DATA_TEST_2015.iteritems():\n",
    "    DATA_TRAIN_2016[filename]=data\n",
    "    \n",
    "for filename in TEST_2016_NAMEFILES:\n",
    "    filename_=make_data_name(TEST_2016_DATADIR,filename,replace=False)\n",
    "    gs,data=read_data_file(filename_,)\n",
    "    DATA_TEST_2016[filename]=(gs,data)\n",
    "    print \"Shape para\",filename,data.shape\n",
    "    \n",
    "print \"Total train data files 2016:\",len(DATA_TRAIN_2016)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape (19842, 16)\n",
      "Training shape (19842,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-28982eb2560a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mX_train_2016\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_2016\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_2016\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train_2016\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \"\"\"\n\u001b[0;32m    194\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[1;31m# Pre-sort indices to avoid that each individual tree of the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features)\u001b[0m\n\u001b[0;32m    344\u001b[0m                              array.ndim)\n\u001b[0;32m    345\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     50\u001b[0m             and not np.isfinite(X).all()):\n\u001b[0;32m     51\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[1;32m---> 52\u001b[1;33m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "X_train_2016=[]\n",
    "Y_train_2016=[]\n",
    "\n",
    "for filename,(gs,data) in DATA_TRAIN_2016.iteritems():\n",
    "    X_train_2016.append(data)\n",
    "    Y_train_2016.append(gs)\n",
    "X_train_2016=np.concatenate(X_train_2016,axis=0)\n",
    "Y_train_2016=np.concatenate(Y_train_2016,axis=0)\n",
    "\n",
    "\n",
    "print \"Training shape\", X_train_2016.shape\n",
    "print \"Training shape\", Y_train_2016.shape\n",
    "    \n",
    "\n",
    "X_train_2016=np.nan_to_num(X_train_2016)\n",
    "rf= RandomForestRegressor(n_estimators=10)\n",
    "rf.fit(X_train_2016,Y_train_2016)\n",
    "\n",
    "\n",
    "for filename,(gs,data) in DATA_TEST_2016.iteritems():\n",
    "    gs_=rf.predict(data)\n",
    "    print \"Testing shape\",filename,data.shape\n",
    "    filename_=os.path.join(\"..\",OUTPUT_DIR,filename)\n",
    "    fn=open(filename_,'w')\n",
    "    for pred in gs_: \n",
    "        print >> fn, \"{0:1.3f}\".format(pred)\n",
    "    fn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
